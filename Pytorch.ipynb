{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Pytorch.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyO4Qa0FZrDPGvtC58PIbAZZ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/franciscovillaescusa/ML_lectures/blob/main/Pytorch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_cfwTEquCfGG"
      },
      "source": [
        "# Pytorch\n",
        "\n",
        "PyTorch is a Python-based scientific computing package serving two broad purposes:\n",
        "\n",
        "- A replacement for NumPy to use the power of GPUs and other accelerators.\n",
        "- An automatic differentiation library that is useful to implement neural networks."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Io1FpiGmFjIj"
      },
      "source": [
        "Load the relevant libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3nxtFanzCawt"
      },
      "source": [
        "import torch\n",
        "import numpy as np"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lMsdrZJsHJQZ"
      },
      "source": [
        "#### Do some basic operations"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dNXqZU_MHI5P"
      },
      "source": [
        "# define a tensor manually\n",
        "t = torch.tensor([1.4, 2.2, 3.5])\n",
        "\n",
        "# move if from a numpy array\n",
        "a  = np.random.random((10,1))             #define the numpy array\n",
        "t1 = torch.tensor(a)                      #create tensor; data type is the same as numpy array\n",
        "t2 = torch.tensor(a, dtype=torch.float32) #specify data type if needed\n",
        "t3 = torch.Tensor(a)                      #same as t1 but will set dtype to be float32 (standard pytorch dtype)\n",
        "t4 = torch.as_tensor(a)                   #same dtype as numpy array\n",
        "t5 = torch.from_numpy(a)                  #same dtype as numpy array\n",
        "# t1, t2, and t3 will create a copy of the data a\n",
        "# t4 and t5 will share the data with a\n",
        "\n",
        "# lets see the data and their type\n",
        "print('a=',a)\n",
        "print('a type:',a.dtype)\n",
        "print('t1=',t1)\n",
        "print('data type:',t1.dtype)\n",
        "print('t1=',t1) \n",
        "print('data type:',t2.dtype)\n",
        "print('t2=',t2) \n",
        "print('data type:',t3.dtype)\n",
        "print('t3=',t3) \n",
        "print('data type:',t4.dtype)\n",
        "print('t5=',t5) \n",
        "print('data type:',t5.dtype)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kaENFE3zuuto"
      },
      "source": [
        "#### Lets see how to visualize tensor properties"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bn3EQWi5SQAa",
        "outputId": "63ebda63-605a-4ccc-cc6d-fbd780634a32"
      },
      "source": [
        "# tensor attributes\n",
        "print('t2 shape:',t2.shape)\n",
        "print('t2 type:',t2.dtype)\n",
        "print('device where t2 is:',t2.device)\n",
        "print('t2 layout:',t2.layout)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "t2 shape: torch.Size([10, 1])\n",
            "t2 type: torch.float32\n",
            "device where t2 is: cpu\n",
            "t2 layout: torch.strided\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SKT_Xv3Rya8T"
      },
      "source": [
        "#### Some useful pytorch functions to operate with tensors"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NoAji_B9u8CC"
      },
      "source": [
        "a = torch.eye(2)     #creates diagonal matrix with 2x2 elements: [[1.,0.],[0.,1.]]\n",
        "b = torch.zeros(2,2) #fill a 2x2 matrix with zeros\n",
        "c = torch.ones(2,2)  #fill a 2x2 matrix with ones\n",
        "d = torch.rand(2,2)  #2x2 matrix with random values\n",
        "print(a)\n",
        "print(b)\n",
        "print(c)\n",
        "print(d)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hLovBOerzF9s"
      },
      "source": [
        "# move the tensor to the GPU\n",
        "t = t.cuda()                    \n",
        "device = torch.device('cuda:1') #move to the second GPU\n",
        "\n",
        "# move a tensor to numpy array\n",
        "t.numpy()\n",
        "\n",
        "# reshape/stack \n",
        "t.reshape(2,5)\n",
        "t.reshape(1,-1) #for the second dimension pytorch will figure out the correct number\n",
        "t.reshape(-1);  t.squeeze();  t.flatten();  t.view(t.numel())  #create a 1D tensor\n",
        "t.flatten(start_dim=1);  #flatten only from first dimension\n",
        "t = torch.stack((t1,t2,t3))\n",
        "\n",
        "# Pytorch only supports operations between same data type tensors (float,int...)\n",
        "\n",
        "# images are represented in Pytorch as [batch, color, height, width]\n",
        "\n",
        "# this will work\n",
        "t1 = torch.tensor([[1,1],[1,1]], dtype=torch.float32)\n",
        "t2 = torch.tensor([2,4], dtype=torch.float32)\n",
        "t1 + t2\n",
        "# t2 is broadcasted to the shape of t1. To see what it is doing use this\n",
        "np.broadcast_to(t2.numpy(), t1.shape)\n",
        "\n",
        "# conditional operations (0-False, 1-True)\n",
        "t = torch.tensor([[1,2,3],[-1,2,0],[3,-8,7]], dtype=torch.float32)\n",
        "t.eq(0)  #where the tensor is equal to 0\n",
        "t.ge(0)  #where the tensor is equal or greater than 0\n",
        "t.gt(0)  #where the tensor is greater than 0\n",
        "t.lt(0)  #where the tensor is less than \n",
        "t.le(0)  #where the tensor is equal or less than 0\n",
        "\n",
        "# other operations\n",
        "t.abs()\n",
        "t.sqrt()\n",
        "t.neg()  #return the negative values of the tensor\n",
        "t.sum();  t.sum(dim=0)\n",
        "t.prod() #product of all elements\n",
        "t.mean()\n",
        "t.std()\n",
        "t.max();  t.max(dim=0)\n",
        "t.argmax() #gives the index of the maximum value in t\n",
        "t.t() #transpose of a tensor\n",
        "\n",
        "# get the value of a tensor\n",
        "t.mean().item()\n",
        "\n",
        "# random numbers\n",
        "seed = 1\n",
        "torch.manual_seed(seed)\n",
        "\n",
        "\n",
        "\n",
        "#################################################################################################\n",
        "#################################################################################################\n",
        "\n",
        "# define a tensor as part of graph\n",
        "a = torch.tensor([1.0, 2.0, 3.0], requires_grad=True)\n",
        "\n",
        "# check if a tensor has gradients\n",
        "a.requires_grad"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}